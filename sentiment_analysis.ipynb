{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d8256d-d53f-4d5d-80c4-8dc2699f9420",
   "metadata": {},
   "source": [
    "# Análise de Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03d259-d969-4797-9051-51e5302aa21f",
   "metadata": {},
   "source": [
    "**Objetivos**\n",
    " - Importar dados de comentários para treinar a máquina a prever e avaliar dados futuros.\n",
    " - Fazer o pré-processamento de texto adequadamente para análise de sentimento\n",
    " - Treinar o modelo vetorizado usando TF-ID com N-Gramas\n",
    " - Avaliar métricas de acurácia, precisão, recal e F1 score.\n",
    " - Aplicar o aprendizado para prever novos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c941b-2d0a-4d71-a75a-1e47b04af29b",
   "metadata": {},
   "source": [
    "## Importando bibliotecas\n",
    "Para este projeto, irei utilizar um grande conjunto de bibliotecas:\n",
    "- **Manipulação de dados:**\n",
    "  - `pandas` para manipular meus dados e preparar o DataFrame para PLN\n",
    "      \n",
    "**Pré-Processamento de texto:**\n",
    "  - `re` para remoção de diversos caracteres\n",
    "  - `spacy` para lematização de palavras da lingua portuguesa\n",
    "  - `nltk` para remoção de stopwords, tokenização e lematização\n",
    "  - `unidecode` para preservar acentuações da lingua portuguesa\n",
    "      \n",
    "**Vetorização e treinamento:**\n",
    " - Várias importações de pacotes do `sklearn` para diversos fins de treinamento e vetorização.\n",
    " \n",
    "**Dependências:**\n",
    " - Serão baixadas algumas dependências para serem aplicadas no pré-processamento     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e55add-782b-48b5-8644-db4df50c3829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Thiago\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Thiago\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Thiago\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Thiago\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84681cb1-fb13-4709-a0be-273a48eec5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando uma função para o pré-processamento de textos em português\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "def pre_processamento_texto(texto, lemmatize=False):\n",
    "    texto = re.sub(r'<.*?>', '', texto) # Remove tags HTML\n",
    "    texto = unidecode(texto) \n",
    "    texto = re.sub(r'[^a-zA-Z0-9\\s]', '', texto) # Remove caracteres especiais\n",
    "    texto = re.sub(r'http\\S+', '', texto) # Remove URLs\n",
    "    texto = re.sub(r'\\s+', ' ', texto) # Remove espaços em branco extras\n",
    "    texto = texto.strip() # Remove espaços em branco no início e no final\n",
    "    texto = texto.lower() # Converte para minúsculas\n",
    "    texto = re.sub(r'\\d+', '', texto) # Remove números\n",
    "    tokens = word_tokenize(texto) # converte o texto para tokens de palavras\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    if lemmatize:\n",
    "        tokens = [token.lemma_ for token in nlp(' '.join(tokens))]\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11298ca6-1fcf-42c4-ace7-2a2776508b2e",
   "metadata": {},
   "source": [
    "## Preparando dados\n",
    "Os dados que serão utilizados para treinamento foram gerados por IA. Mas pretendo utilizar um conjunto de dados maiores para melhores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35570c80-95e2-4d02-ac3d-18c6fc6c2ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   positivo  50 non-null     object\n",
      " 1   negativo  50 non-null     object\n",
      " 2   neutro    50 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Comentarios.csv')\n",
    "df = pd.DataFrame(data)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6703d26-ebfc-4bcd-8507-873d08459576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positivo</th>\n",
       "      <th>negativo</th>\n",
       "      <th>neutro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Este livro foi uma leitura absolutamente incrí...</td>\n",
       "      <td>Este filme foi um desastre total. A atuação er...</td>\n",
       "      <td>O filme tinha uma história interessante, mas a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O restaurante tinha um ambiente agradável e a ...</td>\n",
       "      <td>A comida estava horrível e o serviço foi péssi...</td>\n",
       "      <td>A comida estava ok, nada de muito especial, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adorei a apresentação! Os artistas foram talen...</td>\n",
       "      <td>Fiquei extremamente decepcionado com o produto...</td>\n",
       "      <td>A apresentação teve seus momentos bons e ruins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recebi meu pedido e fiquei muito satisfeito co...</td>\n",
       "      <td>A loja estava suja e desorganizada, e os funci...</td>\n",
       "      <td>O produto era exatamente como estava descrito,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A equipe foi muito atenciosa e prestativa, me ...</td>\n",
       "      <td>A apresentação foi monótona e cansativa. O pal...</td>\n",
       "      <td>A equipe parecia eficiente, mas também não mui...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            positivo  \\\n",
       "0  Este livro foi uma leitura absolutamente incrí...   \n",
       "1  O restaurante tinha um ambiente agradável e a ...   \n",
       "2  Adorei a apresentação! Os artistas foram talen...   \n",
       "3  Recebi meu pedido e fiquei muito satisfeito co...   \n",
       "4  A equipe foi muito atenciosa e prestativa, me ...   \n",
       "\n",
       "                                            negativo  \\\n",
       "0  Este filme foi um desastre total. A atuação er...   \n",
       "1  A comida estava horrível e o serviço foi péssi...   \n",
       "2  Fiquei extremamente decepcionado com o produto...   \n",
       "3  A loja estava suja e desorganizada, e os funci...   \n",
       "4  A apresentação foi monótona e cansativa. O pal...   \n",
       "\n",
       "                                              neutro  \n",
       "0  O filme tinha uma história interessante, mas a...  \n",
       "1  A comida estava ok, nada de muito especial, ma...  \n",
       "2  A apresentação teve seus momentos bons e ruins...  \n",
       "3  O produto era exatamente como estava descrito,...  \n",
       "4  A equipe parecia eficiente, mas também não mui...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e0b8d8-a176-4ee0-9bd2-492003783c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando listas para o novo DataFrame\n",
    "textos = []\n",
    "sentimentos = []\n",
    "\n",
    "# Iterando sobre os dados originais para criar as novas listas\n",
    "for sentimento, lista_textos in data.items():\n",
    "    for texto in lista_textos:\n",
    "        textos.append(texto)\n",
    "        sentimentos.append(sentimento)\n",
    "\n",
    "# Criando o novo DataFrame\n",
    "df_pln = pd.DataFrame({'textos': textos, 'sentimentos': sentimentos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab92bf7-17ab-4621-8c6a-042435df6e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textos</th>\n",
       "      <th>sentimentos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Este livro foi uma leitura absolutamente incrí...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O restaurante tinha um ambiente agradável e a ...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adorei a apresentação! Os artistas foram talen...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recebi meu pedido e fiquei muito satisfeito co...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A equipe foi muito atenciosa e prestativa, me ...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              textos sentimentos\n",
       "0  Este livro foi uma leitura absolutamente incrí...    positivo\n",
       "1  O restaurante tinha um ambiente agradável e a ...    positivo\n",
       "2  Adorei a apresentação! Os artistas foram talen...    positivo\n",
       "3  Recebi meu pedido e fiquei muito satisfeito co...    positivo\n",
       "4  A equipe foi muito atenciosa e prestativa, me ...    positivo"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pln.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163bb74-8092-47ff-af57-3a1b4cecbf88",
   "metadata": {},
   "source": [
    "## Pré-processamento\n",
    "Irei criar uma nova coluna para os textos pré-processados. Durante o processamento, eu evitei a lematização pois estava inteferindo na eficácia da máquina e consequentemente piorando as previsões. Foram feita as remoções dos acentos e do \"ç\", mas preservando as letras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b59def-50af-49e3-ba12-9e5b0a1fcae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textos</th>\n",
       "      <th>sentimentos</th>\n",
       "      <th>textos preprocessados</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Este livro foi uma leitura absolutamente incrí...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>livro leitura absolutamente incrivel historia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O restaurante tinha um ambiente agradável e a ...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>restaurante ambiente agradavel comida simplesm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adorei a apresentação! Os artistas foram talen...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>adorei apresentacao artistas talentosos show d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recebi meu pedido e fiquei muito satisfeito co...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>recebi pedido fiquei satisfeito qualidade prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A equipe foi muito atenciosa e prestativa, me ...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>equipe atenciosa prestativa ajudando todas duv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              textos sentimentos  \\\n",
       "0  Este livro foi uma leitura absolutamente incrí...    positivo   \n",
       "1  O restaurante tinha um ambiente agradável e a ...    positivo   \n",
       "2  Adorei a apresentação! Os artistas foram talen...    positivo   \n",
       "3  Recebi meu pedido e fiquei muito satisfeito co...    positivo   \n",
       "4  A equipe foi muito atenciosa e prestativa, me ...    positivo   \n",
       "\n",
       "                               textos preprocessados  \n",
       "0  livro leitura absolutamente incrivel historia ...  \n",
       "1  restaurante ambiente agradavel comida simplesm...  \n",
       "2  adorei apresentacao artistas talentosos show d...  \n",
       "3  recebi pedido fiquei satisfeito qualidade prod...  \n",
       "4  equipe atenciosa prestativa ajudando todas duv...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar pré-processamento\n",
    "df_pln['textos preprocessados'] = df_pln['textos'].apply(pre_processamento_texto)\n",
    "df_pln.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23035081-e800-4eac-9afc-30c45404ecdc",
   "metadata": {},
   "source": [
    "## Vetorização e Treinamento\n",
    "Com o TF-IDF para vetorizar, utilizei o N-Gramas em `1,2` para preservar a sintaxe das frases.\n",
    "Por alguma razão, a regressão logística obteve melhores resultados do que a multinomialNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94ea3f25-339f-4bed-a724-9201c3e50a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.77\n",
      "Precisão: 0.78\n",
      "Recall: 0.77\n",
      "F1-score: 0.76\n"
     ]
    }
   ],
   "source": [
    "#------------------\n",
    "# Vetorização TF-IDF\n",
    "#------------------\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(df_pln['textos preprocessados'])\n",
    "y = df_pln['sentimentos']\n",
    "\n",
    "#------------------\n",
    "# Divisão dos dados\n",
    "#------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#------------------\n",
    "# Treinamento do modelo (Regressão Logística)\n",
    "#------------------\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#------------------\n",
    "# Avaliação do modelo\n",
    "#------------------\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Acurácia: {accuracy:.2f}\")\n",
    "print(f\"Precisão: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a855015-7f5a-4b6e-8d4e-76148574527d",
   "metadata": {},
   "source": [
    "## Aplicando o Modelo em novos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10894a0e-3bf7-409e-9823-d7567a95af8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentário: Essa pizza é a coisa mais divina que eu experimentei. - Previsão: positivo\n",
      "\n",
      "Comentário: Foi um dos melhores filmes que eu já vi! - Previsão: positivo\n",
      "\n",
      "Comentário: Meu Deus, que comida horrível!! Como é que alguém come isso? - Previsão: negativo\n",
      "\n",
      "Comentário: O serviço foi razoável, nada de extraordinário, mas também não foi ruim. - Previsão: neutro\n",
      "\n",
      "Comentário: Este filme é tão ruim que chega a ser engraçado, mas não no bom sentido. - Previsão: negativo\n",
      "\n",
      "Comentário: Estou simplesmente apaixonado por este produto! A qualidade, o design e o atendimento superaram todas as minhas expectativas. - Previsão: positivo\n",
      "\n",
      "Comentário: A reunião foi adiada, mas não sei se isso é bom ou ruim. - Previsão: neutro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#------------------\n",
    "# Teste com novos dados\n",
    "#------------------\n",
    "novos_coments = [\n",
    "    \"Essa pizza é a coisa mais divina que eu experimentei.\",\n",
    "    \"Foi um dos melhores filmes que eu já vi!\",\n",
    "    \"Meu Deus, que comida horrível!! Como é que alguém come isso?\",\n",
    "    \"O serviço foi razoável, nada de extraordinário, mas também não foi ruim.\",\n",
    "    \"Este filme é tão ruim que chega a ser engraçado, mas não no bom sentido.\",\n",
    "    \"Estou simplesmente apaixonado por este produto! A qualidade, o design e o atendimento superaram todas as minhas expectativas.\",\n",
    "    \"A reunião foi adiada, mas não sei se isso é bom ou ruim.\"\n",
    "]\n",
    "novos_coments_preprocessados = [pre_processamento_texto(review) for review in new_reviews]\n",
    "novos_coments_vetorizados = vectorizer.transform(novos_coments_preprocessados)\n",
    "novos_coments_previsao = model.predict(novos_coments_vetorizados)\n",
    "\n",
    "for review, prediction in zip(novos_coments, novos_coments_previsao):\n",
    "    print(f\"Comentário: {review} - Previsão: {prediction}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
